"""
ĞœĞ¾Ğ´ÑƒĞ»ÑŒ Ğ´Ğ»Ñ Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ¸Ñ Ğ¼Ğ¾Ğ´ĞµĞ»ĞµĞ¹ LightGBM Ğ¸ RandomForest Ñ Ğ¸ÑĞ¿Ğ¾Ğ»ÑŒĞ·Ğ¾Ğ²Ğ°Ğ½Ğ¸ĞµĞ¼ Optuna
Ğ¸ SHAP-Ñ„Ğ¸Ğ»ÑŒÑ‚Ñ€Ğ°Ñ†Ğ¸ĞµĞ¹ Ğ¿Ñ€Ğ¸Ğ·Ğ½Ğ°ĞºĞ¾Ğ². ĞŸĞ¾Ğ´Ğ´ĞµÑ€Ğ¶Ğ¸Ğ²Ğ°ĞµÑ‚ Ğ¸ÑĞ¿Ğ¾Ğ»ÑŒĞ·Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğµ Ğ² DVC-Ğ¿Ğ°Ğ¹Ğ¿Ğ»Ğ°Ğ¹Ğ½Ğµ.
"""

import os
import sys
import time
import pickle
import argparse
import warnings

import numpy as np
import pandas as pd
import shap
import optuna

from sklearn.model_selection import train_test_split, cross_val_score
from sklearn.metrics import roc_auc_score
from sklearn.pipeline import Pipeline
from sklearn.compose import ColumnTransformer
from sklearn.linear_model import LogisticRegression
from sklearn.preprocessing import StandardScaler, OneHotEncoder
from sklearn.ensemble import RandomForestClassifier
import lightgbm as lgb


RANDOM_STATE = 42
warnings.filterwarnings("ignore")

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# 1. Ğ—Ğ°Ğ³Ñ€ÑƒĞ·ĞºĞ° Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ…
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

def load_and_merge_data(application_path: str, bureau_path: str):
    """
    Ğ—Ğ°Ğ³Ñ€ÑƒĞ¶Ğ°ĞµÑ‚ Ğ´Ğ°Ğ½Ğ½Ñ‹Ğµ Ğ¸Ğ· Ğ´Ğ²ÑƒÑ… Ñ„Ğ°Ğ¹Ğ»Ğ¾Ğ² (application + bureau_balance) Ğ¸ Ğ¾Ğ±ÑŠĞµĞ´Ğ¸Ğ½ÑĞµÑ‚
    """
    print("[INFO] Ğ—Ğ°Ğ³Ñ€ÑƒĞ·ĞºĞ° Ğ¸ Ğ¾Ğ±ÑŠĞµĞ´Ğ¸Ğ½ĞµĞ½Ğ¸Ğµ Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ…...")

    bureau_balance = pd.read_csv(bureau_path)
    df = pd.read_csv(application_path)

    test = df[df["target"].isnull()].copy()
    train = df[df["target"].notnull()].copy()

    nan_thresh = 0.15
    valid_cols = (train.isnull().mean() <= nan_thresh).index.tolist()
    train = train[valid_cols]
    test = test[valid_cols]

    train = train.merge(bureau_balance, on="sk_id_curr", how="left")
    test = test.merge(bureau_balance, on="sk_id_curr", how="left")

    train.fillna(-1, inplace=True)
    test.fillna(-1, inplace=True)
    test["target"] = np.nan

    return train, test

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# 2. ĞŸĞ¾Ğ´Ğ³Ğ¾Ñ‚Ğ¾Ğ²ĞºĞ° Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ…
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

def preprocess_data(train):
    """
    Ğ”ĞµĞ»Ğ¸Ñ‚ train Ğ½Ğ° X/y Ğ¸ Ğ¾Ğ±Ñ€Ğ°Ğ±Ğ°Ñ‚Ñ‹Ğ²Ğ°ĞµÑ‚ Ğ±Ğ¸Ğ½Ğ°Ñ€Ğ½Ñ‹Ğµ Ğ¿Ñ€Ğ¸Ğ·Ğ½Ğ°ĞºĞ¸
    """
    print("[INFO] ĞŸÑ€ĞµĞ´Ğ¾Ğ±Ñ€Ğ°Ğ±Ğ¾Ñ‚ĞºĞ°...")
    X = train.drop(['target', 'sk_id_curr'], axis=1)
    y = train['target'].astype(int)

    # ĞŸÑ€ĞµĞ¾Ğ±Ñ€Ğ°Ğ·Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğµ Y/N Ğ² 0/1
    for col in ["flag_own_car", "flag_own_realty"]:
        if col in X.columns:
            X[col] = X[col].replace({'Y': 1, 'N': 0})

    return X, y

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# 3. ĞŸÑ€ĞµĞ¿Ñ€Ğ¾Ñ†ĞµÑÑĞ¾Ñ€
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

def build_preprocessing_pipeline(X):
    """
    Ğ’Ğ¾Ğ·Ğ²Ñ€Ğ°Ñ‰Ğ°ĞµÑ‚ ColumnTransformer Ñ Ğ¾Ğ±Ñ€Ğ°Ğ±Ğ¾Ñ‚ĞºĞ¾Ğ¹ Ñ‡Ğ¸ÑĞ»Ğ¾Ğ²Ñ‹Ñ…, Ğ±Ğ¸Ğ½Ğ°Ñ€Ğ½Ñ‹Ñ… Ğ¸ ĞºĞ°Ñ‚ĞµĞ³Ğ¾Ñ€Ğ¸Ğ°Ğ»ÑŒĞ½Ñ‹Ñ… ÑÑ‚Ğ¾Ğ»Ğ±Ñ†Ğ¾Ğ².
    """
    bin_cols = [col for col in X.columns if X[col].nunique() == 2]
    num_cols = list(set(X.select_dtypes(include=["int", "float"]).columns) - set(bin_cols))
    cat_cols = X.select_dtypes(include=["object"]).columns.tolist()

    if cat_cols:
        X[cat_cols] = X[cat_cols].astype(str)

    return ColumnTransformer([
        ("num", StandardScaler(), num_cols),
        ("bin", "passthrough", bin_cols),
        ("cat", OneHotEncoder(handle_unknown="ignore", sparse_output=False), cat_cols)
    ])

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# 4. SHAP-Ñ„Ğ¸Ğ»ÑŒÑ‚Ñ€Ğ°Ñ†Ğ¸Ñ Ğ¿Ñ€Ğ¸Ğ·Ğ½Ğ°ĞºĞ¾Ğ²
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

def select_top_shap_features(X, y, top_n=100):
    """
    ĞĞ±ÑƒÑ‡Ğ°ĞµÑ‚ Ğ±Ğ°Ğ·Ğ¾Ğ²ÑƒÑ Ğ¼Ğ¾Ğ´ĞµĞ»ÑŒ, Ğ²Ñ‹Ñ‡Ğ¸ÑĞ»ÑĞµÑ‚ SHAP Ğ¸ Ğ¾ÑÑ‚Ğ°Ğ²Ğ»ÑĞµÑ‚ Ñ‚Ğ¾Ğ¿-N Ğ¿Ñ€Ğ¸Ğ·Ğ½Ğ°ĞºĞ¾Ğ²
    """
    print("[INFO] ĞÑ‚Ğ±Ğ¾Ñ€ Ğ¿Ñ€Ğ¸Ğ·Ğ½Ğ°ĞºĞ¾Ğ² Ğ¿Ğ¾ SHAP...")

    preprocessor = build_preprocessing_pipeline(X)
    model = lgb.LGBMClassifier(n_estimators=100, random_state=RANDOM_STATE)

    pipeline = Pipeline([("preprocessor", preprocessor), ("model", model)])

    X_train, X_val, y_train, y_val = train_test_split(
        X, y, test_size=0.2, random_state=RANDOM_STATE
    )

    pipeline.fit(X_train, y_train)
    X_transformed = pipeline.named_steps["preprocessor"].transform(X_val)
    feature_names = pipeline.named_steps["preprocessor"].get_feature_names_out()

    explainer = shap.Explainer(pipeline.named_steps["model"])
    shap_values = explainer(X_transformed)

    shap_df = pd.DataFrame({
        'feature': feature_names,
        'importance': np.abs(shap_values.values).mean(axis=0)
    }).sort_values(by="importance", ascending=False)

    top_features = shap_df.head(top_n)["feature"].tolist()
    return top_features, shap_df

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# 5. ĞĞ¿Ñ‚Ğ¸Ğ¼Ğ¸Ğ·Ğ°Ñ†Ğ¸Ñ Ğ¸ Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ¸Ğµ Ğ¼Ğ¾Ğ´ĞµĞ»Ğ¸
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

def optimize_and_train(X, y, selected_features, output_dir="src/app/modelling"):
    """
    ĞĞ¿Ñ‚Ğ¸Ğ¼Ğ¸Ğ·Ğ°Ñ†Ğ¸Ñ Ğ¸ Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ¸Ğµ Ğ¼Ğ¾Ğ´ĞµĞ»ĞµĞ¹ LightGBM Ğ¸ RandomForest Ğ¿Ğ¾ Ğ¾Ñ‚Ğ¾Ğ±Ñ€Ğ°Ğ½Ğ½Ñ‹Ğ¼ Ğ¿Ñ€Ğ¸Ğ·Ğ½Ğ°ĞºĞ°Ğ¼
    """
    X = X.copy()
    X = X[selected_features]

    def objective_lgb(trial):
        params = {
            "objective": "binary",
            "metric": "auc",
            "verbosity": -1,
            "boosting_type": "gbdt",
            "learning_rate": trial.suggest_float("learning_rate", 1e-3, 1e-1, log=True),
            "num_leaves": trial.suggest_int("num_leaves", 15, 128),
            "max_depth": trial.suggest_int("max_depth", 3, 16),
            "min_child_samples": trial.suggest_int("min_child_samples", 10, 100),
            "subsample": trial.suggest_float("subsample", 0.5, 1.0),
            "colsample_bytree": trial.suggest_float("colsample_bytree", 0.5, 1.0),
            "reg_alpha": trial.suggest_float("reg_alpha", 1e-8, 10.0, log=True),
            "reg_lambda": trial.suggest_float("reg_lambda", 1e-8, 10.0, log=True),
            "random_state": RANDOM_STATE
        }
        preproc = build_preprocessing_pipeline(X)
        model = lgb.LGBMClassifier(**params, n_estimators=500)
        pipe = Pipeline([("preprocessor", preproc), ("model", model)])
        score = cross_val_score(pipe, X, y, cv=5, scoring="roc_auc", n_jobs=-1)
        return -np.mean(score)

    def objective_rf(trial):
        params = {
            "n_estimators": trial.suggest_int("n_estimators", 100, 300),
            "max_depth": trial.suggest_int("max_depth", 5, 30),
            "min_samples_split": trial.suggest_int("min_samples_split", 2, 50),
            "min_samples_leaf": trial.suggest_int("min_samples_leaf", 1, 50),
            "max_features": trial.suggest_categorical("max_features", ["sqrt", "log2", None]),
            "class_weight": "balanced",
            "random_state": RANDOM_STATE,
            "n_jobs": -1
        }
        preproc = build_preprocessing_pipeline(X)
        model = RandomForestClassifier(**params)
        pipe = Pipeline([("preprocessor", preproc), ("model", model)])
        score = cross_val_score(pipe, X, y, cv=5, scoring="roc_auc", n_jobs=-1)
        return -np.mean(score)

    print("[INFO] ĞĞ¿Ñ‚Ğ¸Ğ¼Ğ¸Ğ·Ğ°Ñ†Ğ¸Ñ LightGBM")
    study_lgb = optuna.create_study(direction="minimize")
    study_lgb.optimize(objective_lgb, n_trials=20, n_jobs=2)

    print("[INFO] ĞĞ¿Ñ‚Ğ¸Ğ¼Ğ¸Ğ·Ğ°Ñ†Ğ¸Ñ RandomForest")
    study_rf = optuna.create_study(direction="minimize")
    study_rf.optimize(objective_rf, n_trials=20, n_jobs=2)

    # ĞÑ†ĞµĞ½ĞºĞ° Ñ€ĞµĞ·ÑƒĞ»ÑŒÑ‚Ğ°Ñ‚Ğ¾Ğ²
    best_lgb = lgb.LGBMClassifier(**study_lgb.best_params, n_estimators=500, random_state=RANDOM_STATE)
    best_rf = RandomForestClassifier(**study_rf.best_params, class_weight="balanced", random_state=RANDOM_STATE)

    pipe_lgb = Pipeline([("preprocessor", build_preprocessing_pipeline(X)), ("model", best_lgb)])
    pipe_rf = Pipeline([("preprocessor", build_preprocessing_pipeline(X)), ("model", best_rf)])

    auc_lgb = cross_val_score(pipe_lgb, X, y, cv=10, scoring="roc_auc").mean()
    auc_rf = cross_val_score(pipe_rf, X, y, cv=10, scoring="roc_auc").mean()

    print(f"LightGBM AUC: {auc_lgb:.4f}")
    print(f"RandomForest AUC: {auc_rf:.4f}")

    best_pipe = pipe_lgb if auc_lgb > auc_rf else pipe_rf
    best_name = "lightgbm" if auc_lgb > auc_rf else "randomforest"

    os.makedirs(output_dir, exist_ok=True)
    pickle.dump(best_pipe, open(f"{output_dir}/final_model_{best_name}.pkl", "wb"))
    print(f"[âœ…] ĞœĞ¾Ğ´ĞµĞ»ÑŒ ÑĞ¾Ñ…Ñ€Ğ°Ğ½ĞµĞ½Ğ° ĞºĞ°Ğº final_model_{best_name}.pkl")


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# 6. ĞÑĞ½Ğ¾Ğ²Ğ½Ğ°Ñ Ñ„ÑƒĞ½ĞºÑ†Ğ¸Ñ
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

def main():
    start = time.time()

    parser = argparse.ArgumentParser()
    parser.add_argument("--application_file", required=True,
                        help="ĞŸÑƒÑ‚ÑŒ Ğ´Ğ¾ features_application_train_test.csv")
    parser.add_argument("--bureau_balance_file", required=True,
                        help="ĞŸÑƒÑ‚ÑŒ Ğ´Ğ¾ features_bureau_balance.csv")
    parser.add_argument("--output_file", required=True,
                        help="ĞŸÑƒÑ‚ÑŒ Ğ´Ğ»Ñ ÑĞ¾Ñ…Ñ€Ğ°Ğ½ĞµĞ½Ğ¸Ñ SHAP Ğ²Ğ°Ğ¶Ğ½Ğ¾ÑÑ‚ĞµĞ¹")
    args = parser.parse_args()

    train, _ = load_and_merge_data(args.application_file, args.bureau_balance_file)
    X, y = preprocess_data(train)

    top_features, shap_df = select_top_shap_features(X, y, top_n=100)
    shap_df.to_csv(args.output_file, index=False)
    print(f"[ğŸ“ˆ] SHAP Ğ²Ğ°Ğ¶Ğ½Ğ¾ÑÑ‚Ğ¸ ÑĞ¾Ñ…Ñ€Ğ°Ğ½ĞµĞ½Ñ‹: {args.output_file}")

    optimize_and_train(X, y, selected_features=top_features)

    print(f"[â±] Ğ’Ñ€ĞµĞ¼Ñ Ğ²Ñ‹Ğ¿Ğ¾Ğ»Ğ½ĞµĞ½Ğ¸Ñ: {time.time() - start:.2f} ÑĞµĞº.")


if __name__ == "__main__":
    main()
